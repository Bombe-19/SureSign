{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Import necessary libraries**"
      ],
      "metadata": {
        "id": "jjRUD8cB5QHm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_KPEmZwvhb-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from collections import OrderedDict\n",
        "from math import factorial\n",
        "from copy import deepcopy\n",
        "import pickle\n",
        "import random\n",
        "import skimage.io as sk\n",
        "from skimage import img_as_ubyte\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from keras import backend as K\n",
        "from keras.layers import Input, Lambda, Dense, Dropout, Convolution2D, MaxPooling2D, Flatten,Activation\n",
        "from keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import callbacks\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
        "from keras.models import Model,load_model, model_from_json\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Define the Forgeries Signature**"
      ],
      "metadata": {
        "id": "eJwgsBM95Tze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image1 = sk.imread(\"/content/drive/MyDrive/Data/signatures/signatures_1/forgeries_1_1.png\")\n",
        "image2 = sk.imread(\"/content/drive/MyDrive/Data/signatures/signatures_1/forgeries_1_20.png\")\n",
        "image3 = sk.imread(\"/content/drive/MyDrive/Data/signatures/signatures_1/forgeries_1_21.png\")\n",
        "image4 = sk.imread(\"/content/drive/MyDrive/Data/signatures/signatures_1/forgeries_1_22.png\")\n",
        "image5 = sk.imread(\"/content/drive/MyDrive/Data/signatures/signatures_1/forgeries_1_23.png\")\n",
        "image6 = sk.imread(\"/content/drive/MyDrive/Data/signatures/signatures_11/forgeries_11_1.png\")\n",
        "image7 = sk.imread(\"/content/drive/MyDrive/Data/signatures/signatures_11/forgeries_11_20.png\")\n",
        "image8 = sk.imread(\"/content/drive/MyDrive/Data/signatures/signatures_11/forgeries_11_21.png\")\n",
        "image9 = sk.imread(\"/content/drive/MyDrive/Data/signatures/signatures_11/forgeries_11_22.png\")\n",
        "image10 = sk.imread(\"/content/drive/MyDrive/Data/signatures/signatures_11/forgeries_11_23.png\")\n",
        "\n",
        "fig, ax = plt.subplots(2,5, figsize = (15,10))\n",
        "plt.subplots_adjust(hspace=0)\n",
        "\n",
        "ax[0,0].imshow(image1)\n",
        "ax[0,0].set_title(\"Forge_1\")\n",
        "ax[0,1].imshow(image2)\n",
        "ax[0,1].set_title(\"Forge_20\")\n",
        "ax[0,2].imshow(image3)\n",
        "ax[0,2].set_title(\"Forge_21\")\n",
        "ax[0,3].imshow(image4)\n",
        "ax[0,3].set_title(\"Forge_22\")\n",
        "ax[0,4].imshow(image5)\n",
        "ax[0,4].set_title(\"Forge_23\")\n",
        "ax[1,0].imshow(image6)\n",
        "ax[1,0].set_title(\"Forge_1\")\n",
        "ax[1,1].imshow(image7)\n",
        "ax[1,1].set_title(\"Forge_20\")\n",
        "ax[1,2].imshow(image8)\n",
        "ax[1,2].set_title(\"Forge_21\")\n",
        "ax[1,3].imshow(image9)\n",
        "ax[1,3].set_title(\"Forge_22\")\n",
        "ax[1,4].imshow(image10)\n",
        "ax[1,4].set_title(\"Forge_23\")"
      ],
      "metadata": {
        "id": "OIF9zNRYvmG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Preprocess the forgeries image**"
      ],
      "metadata": {
        "id": "fiXsYsjE5Wh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def preprocess_image(image):\n",
        "    # Convert to grayscale if it's a color image\n",
        "    if len(image.shape) == 3:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # Resize the image\n",
        "    img = cv2.resize(image, (256, 128))\n",
        "    # Apply Gaussian Blur to remove noise\n",
        "    img = cv2.GaussianBlur(img, (5, 5), 0)\n",
        "    # Apply adaptive thresholding\n",
        "    img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
        "    return img\n",
        "\n",
        "preprocessed_image1 = preprocess_image(image1)\n",
        "preprocessed_image2 = preprocess_image(image2)\n",
        "preprocessed_image3 = preprocess_image(image3)\n",
        "preprocessed_image4 = preprocess_image(image4)\n",
        "preprocessed_image5 = preprocess_image(image5)\n",
        "preprocessed_image6 = preprocess_image(image6)\n",
        "preprocessed_image7 = preprocess_image(image7)\n",
        "preprocessed_image8 = preprocess_image(image8)\n",
        "preprocessed_image9 = preprocess_image(image9)\n",
        "preprocessed_image10 = preprocess_image(image10)\n",
        "\n",
        "fig, ax = plt.subplots(2,5, figsize = (15,10))\n",
        "plt.subplots_adjust(hspace=0)\n",
        "\n",
        "ax[0,0].imshow(preprocessed_image1, cmap='gray')\n",
        "ax[0,0].set_title(\"Forge_1\")\n",
        "ax[0,1].imshow(preprocessed_image2, cmap='gray')\n",
        "ax[0,1].set_title(\"Forge_20\")\n",
        "ax[0,2].imshow(preprocessed_image3, cmap='gray')\n",
        "ax[0,2].set_title(\"Forge_21\")\n",
        "ax[0,3].imshow(preprocessed_image4, cmap='gray')\n",
        "ax[0,3].set_title(\"Forge_22\")\n",
        "ax[0,4].imshow(preprocessed_image5, cmap='gray')\n",
        "ax[0,4].set_title(\"Forge_23\")\n",
        "ax[1,0].imshow(preprocessed_image6, cmap='gray')\n",
        "ax[1,0].set_title(\"Forge_1\")\n",
        "ax[1,1].imshow(preprocessed_image7, cmap='gray')\n",
        "ax[1,1].set_title(\"Forge_20\")\n",
        "ax[1,2].imshow(preprocessed_image8, cmap='gray')\n",
        "ax[1,2].set_title(\"Forge_21\")\n",
        "ax[1,3].imshow(preprocessed_image9, cmap='gray')\n",
        "ax[1,3].set_title(\"Forge_22\")\n",
        "ax[1,4].imshow(preprocessed_image10, cmap='gray')\n",
        "ax[1,4].set_title(\"Forge_23\")"
      ],
      "metadata": {
        "id": "RecXewuvvpHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Define the original images**"
      ],
      "metadata": {
        "id": "Pj_DtP3V5Z-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image11 = sk.imread(\"/content/drive/MyDrive/Data/signatures/signatures_1/original_1_1.png\")\n",
        "image12 = sk.imread(\"/content/drive/MyDrive/Data/signatures/signatures_1/original_1_20.png\")\n",
        "image13 = sk.imread(\"/content/drive/MyDrive/Data/signatures/signatures_1/original_1_21.png\")\n",
        "image14 = sk.imread(\"/content/drive/MyDrive/Data/signatures/signatures_1/original_1_22.png\")\n",
        "image15 = sk.imread(\"/content/drive/MyDrive/Data/signatures/signatures_1/original_1_23.png\")\n",
        "image16 = sk.imread(\"/content/drive/MyDrive/Data/signatures/signatures_11/original_11_1.png\")\n",
        "image17 = sk.imread(\"/content/drive/MyDrive/Data/signatures/signatures_11/original_11_20.png\")\n",
        "image18 = sk.imread(\"/content/drive/MyDrive/Data/signatures/signatures_11/original_11_21.png\")\n",
        "image19 = sk.imread(\"/content/drive/MyDrive/Data/signatures/signatures_11/original_11_22.png\")\n",
        "image20 = sk.imread(\"/content/drive/MyDrive/Data/signatures/signatures_11/original_11_23.png\")\n",
        "\n",
        "fig, ax = plt.subplots(2,5, figsize = (15,10))\n",
        "plt.subplots_adjust(hspace=0)\n",
        "\n",
        "ax[0,0].imshow(image11)\n",
        "ax[0,0].set_title(\"Real_1\")\n",
        "ax[0,1].imshow(image12)\n",
        "ax[0,1].set_title(\"Real_20\")\n",
        "ax[0,2].imshow(image13)\n",
        "ax[0,2].set_title(\"Real_21\")\n",
        "ax[0,3].imshow(image14)\n",
        "ax[0,3].set_title(\"Real_22\")\n",
        "ax[0,4].imshow(image15)\n",
        "ax[0,4].set_title(\"Real_23\")\n",
        "ax[1,0].imshow(image16)\n",
        "ax[1,0].set_title(\"Real_1\")\n",
        "ax[1,1].imshow(image17)\n",
        "ax[1,1].set_title(\"Real_20\")\n",
        "ax[1,2].imshow(image18)\n",
        "ax[1,2].set_title(\"Real_21\")\n",
        "ax[1,3].imshow(image19)\n",
        "ax[1,3].set_title(\"Real_22\")\n",
        "ax[1,4].imshow(image20)\n",
        "ax[1,4].set_title(\"Real_23\")"
      ],
      "metadata": {
        "id": "l3hxFotqvp3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Preproecess the Original image**"
      ],
      "metadata": {
        "id": "lLa_BGC_5cnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image):\n",
        "    # Convert to grayscale if it's a color image\n",
        "    if len(image.shape) == 3:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # Resize the image\n",
        "    img = cv2.resize(image, (256, 128))\n",
        "    # Apply Gaussian Blur to remove noise\n",
        "    img = cv2.GaussianBlur(img, (5, 5), 0)\n",
        "    # Apply adaptive thresholding\n",
        "    img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
        "    return img\n",
        "\n",
        "preprocessed_image11 = preprocess_image(image11)\n",
        "preprocessed_image12 = preprocess_image(image12)\n",
        "preprocessed_image13 = preprocess_image(image13)\n",
        "preprocessed_image14 = preprocess_image(image14)\n",
        "preprocessed_image15 = preprocess_image(image15)\n",
        "preprocessed_image16 = preprocess_image(image16)\n",
        "preprocessed_image17 = preprocess_image(image17)\n",
        "preprocessed_image18 = preprocess_image(image18)\n",
        "preprocessed_image19 = preprocess_image(image19)\n",
        "preprocessed_image20 = preprocess_image(image20)\n",
        "\n",
        "fig, ax = plt.subplots(2,5, figsize = (15,10))\n",
        "plt.subplots_adjust(hspace=0)\n",
        "\n",
        "ax[0,0].imshow(preprocessed_image11, cmap='gray')\n",
        "ax[0,0].set_title(\"Real_1\")\n",
        "ax[0,1].imshow(preprocessed_image12, cmap='gray')\n",
        "ax[0,1].set_title(\"Real_20\")\n",
        "ax[0,2].imshow(preprocessed_image13, cmap='gray')\n",
        "ax[0,2].set_title(\"Real_21\")\n",
        "ax[0,3].imshow(preprocessed_image14, cmap='gray')\n",
        "ax[0,3].set_title(\"Real_22\")\n",
        "ax[0,4].imshow(preprocessed_image15, cmap='gray')\n",
        "ax[0,4].set_title(\"Real_23\")\n",
        "ax[1,0].imshow(preprocessed_image16, cmap='gray')\n",
        "ax[1,0].set_title(\"Real_1\")\n",
        "ax[1,1].imshow(preprocessed_image17, cmap='gray')\n",
        "ax[1,1].set_title(\"Real_20\")\n",
        "ax[1,2].imshow(preprocessed_image18, cmap='gray')\n",
        "ax[1,2].set_title(\"Real_21\")\n",
        "ax[1,3].imshow(preprocessed_image19, cmap='gray')\n",
        "ax[1,3].set_title(\"Real_22\")\n",
        "ax[1,4].imshow(preprocessed_image20, cmap='gray')\n",
        "ax[1,4].set_title(\"Real_23\")"
      ],
      "metadata": {
        "id": "h0arxHY7vtFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Structure the images as geninue and forgery**"
      ],
      "metadata": {
        "id": "bib0Ty335fcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def organize_preprocessed_data():\n",
        "    \"\"\"\n",
        "    Organize your preprocessed images into proper data structure\n",
        "    \"\"\"\n",
        "    genuine_signatures = [\n",
        "        preprocessed_image11, preprocessed_image12, preprocessed_image13,\n",
        "        preprocessed_image14, preprocessed_image15, preprocessed_image16,\n",
        "        preprocessed_image17, preprocessed_image18, preprocessed_image19,\n",
        "        preprocessed_image20\n",
        "    ]\n",
        "\n",
        "    forgery_signatures = [\n",
        "        preprocessed_image1, preprocessed_image2, preprocessed_image3,\n",
        "        preprocessed_image4, preprocessed_image5, preprocessed_image6,\n",
        "        preprocessed_image7, preprocessed_image8, preprocessed_image9,\n",
        "        preprocessed_image10\n",
        "    ]\n",
        "\n",
        "    return genuine_signatures, forgery_signatures"
      ],
      "metadata": {
        "id": "daiaD1ZcvvGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **For SNN we need to feed two inputs we need to pair the images**"
      ],
      "metadata": {
        "id": "79-o5qQf5ifZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_signature_pairs(genuine_signatures, forgery_signatures):\n",
        "    pairs = []\n",
        "    labels = []\n",
        "\n",
        "    # Positive pairs (genuine-genuine)\n",
        "    for i in range(len(genuine_signatures)):\n",
        "        for j in range(i+1, len(genuine_signatures)):\n",
        "            pairs.append([genuine_signatures[i], genuine_signatures[j]])\n",
        "            labels.append(1)  # same person\n",
        "\n",
        "    # Negative pairs (genuine-forgery)\n",
        "    for i in range(len(genuine_signatures)):\n",
        "        pairs.append([genuine_signatures[i], forgery_signatures[i]])\n",
        "        labels.append(0)  # different (forged)\n",
        "\n",
        "    pairs = np.array(pairs)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    indices = np.arange(len(pairs))\n",
        "    np.random.shuffle(indices)\n",
        "    pairs = pairs[indices]\n",
        "    labels = labels[indices]\n",
        "\n",
        "    # Split into two arrays: X1 and X2 for Siamese input\n",
        "    X1 = pairs[:, 0]\n",
        "    X2 = pairs[:, 1]\n",
        "\n",
        "    return X1, X2, labels"
      ],
      "metadata": {
        "id": "SZ1Q6d3Mv79j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Spit the data and train**"
      ],
      "metadata": {
        "id": "la4SPxjp5mTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load and pair your images\n",
        "genuine, forgery = organize_preprocessed_data()\n",
        "X1, X2, y = create_signature_pairs(genuine, forgery)\n",
        "\n",
        "# Normalize\n",
        "X1 = X1.astype('float32') / 255.0\n",
        "X2 = X2.astype('float32') / 255.0\n",
        "\n",
        "# Train-test split (with stratify for balanced classes)\n",
        "X1_train, X1_test, X2_train, X2_test, y_train, y_test = train_test_split(\n",
        "    X1, X2, y, test_size=0.3, random_state=42, stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "WwQRVbOzv-rO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train:\", np.unique(y_train, return_counts=True))\n",
        "print(\"Test:\", np.unique(y_test, return_counts=True))\n"
      ],
      "metadata": {
        "id": "2JfApqBAwAn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Create a base CNN and define the similarty method**"
      ],
      "metadata": {
        "id": "jCNeIf_A5sbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "def create_base_cnn(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Conv2D(64, (10, 10), activation='relu')(inputs)\n",
        "    x = MaxPooling2D()(x)\n",
        "    x = Conv2D(128, (7, 7), activation='relu')(x)\n",
        "    x = MaxPooling2D()(x)\n",
        "    x = Conv2D(128, (4, 4), activation='relu')(x)\n",
        "    x = MaxPooling2D()(x)\n",
        "    x = Conv2D(256, (4, 4), activation='relu')(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(4096, activation='sigmoid')(x)\n",
        "    return Model(inputs, x)\n",
        "\n",
        "# Define L1 Distance function\n",
        "def l1_distance(vectors):\n",
        "    x, y = vectors\n",
        "    return K.abs(x - y)\n",
        "\n",
        "def build_siamese_network(input_shape):\n",
        "    base_cnn = create_base_cnn(input_shape)\n",
        "\n",
        "    input_a = Input(shape=input_shape)\n",
        "    input_b = Input(shape=input_shape)\n",
        "\n",
        "    encoded_a = base_cnn(input_a)\n",
        "    encoded_b = base_cnn(input_b)\n",
        "\n",
        "    # Calculate L1 distance between the encoded vectors\n",
        "    l1_layer = Lambda(l1_distance)([encoded_a, encoded_b])\n",
        "\n",
        "    # Add the output layer\n",
        "    output = Dense(1, activation='sigmoid')(l1_layer)\n",
        "\n",
        "    model = Model(inputs=[input_a, input_b], outputs=output)\n",
        "    return model"
      ],
      "metadata": {
        "id": "_VTIcEV3wDy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Fit the model(Train)**"
      ],
      "metadata": {
        "id": "TV5mgC6c5wg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_siamese_network((128, 256, 1))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit([X1_train, X2_train], y_train,\n",
        "                    batch_size=8, epochs=10, validation_split=0.1)\n"
      ],
      "metadata": {
        "id": "ZBHYkD06wEhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(np.unique(y_test, return_counts=True))"
      ],
      "metadata": {
        "id": "gcLAtILzxxIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Checking the accuracy**"
      ],
      "metadata": {
        "id": "JRY9CC-O50X8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, classification_report\n",
        "\n",
        "# Accuracy\n",
        "loss, acc = model.evaluate([X1_test, X2_test], y_test)\n",
        "print(f\"Test Accuracy: {acc*100:.2f}%\")\n",
        "\n",
        "# ROC AUC + F1\n",
        "y_pred = model.predict([X1_test, X2_test])\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred))\n",
        "print(classification_report(y_test, (y_pred > 0.5).astype(int)))"
      ],
      "metadata": {
        "id": "Z66aj6P9xzRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Validating the ouput**"
      ],
      "metadata": {
        "id": "pE-Uowuh51Wr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_signature(preprocessed_image1, preprocessed_image2, model, threshold=0.6):\n",
        "    sig1 = np.expand_dims(preprocessed_image1, axis=0)\n",
        "    sig1 = np.expand_dims(sig1, axis=-1)\n",
        "    sig2 = np.expand_dims(preprocessed_image13, axis=0)\n",
        "    sig2 = np.expand_dims(sig2, axis=-1)\n",
        "\n",
        "    score = model.predict([sig1, sig2])[0][0]\n",
        "    print(f\"Similarity Score: {score:.4f}\")\n",
        "    print(\"âœ… Genuine\" if score < threshold else \"âŒ Forged\")\n",
        "verify_signature(preprocessed_image1, preprocessed_image2, model)"
      ],
      "metadata": {
        "id": "n8CJGGC4x1ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Define the Custom objects**"
      ],
      "metadata": {
        "id": "vmGhUC48652q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Layer\n",
        "import tensorflow as tf\n",
        "\n",
        "# Euclidean Distance function used in Siamese Networks\n",
        "def euclidean_distance(vectors):\n",
        "    x, y = vectors\n",
        "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
        "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
        "\n",
        "# Contrastive Loss Function\n",
        "def contrastive_loss(y_true, y_pred):\n",
        "    margin = 1.0\n",
        "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n"
      ],
      "metadata": {
        "id": "_1FQvvEbx2V4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Save the model(Locally) for validation**"
      ],
      "metadata": {
        "id": "J8dNWxQh7A4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('siamese_model2.h5')\n"
      ],
      "metadata": {
        "id": "pw5BFj3Ox82s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Checking the ouput**"
      ],
      "metadata": {
        "id": "qlAXIF2i7H7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Layer\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define and register the l1_distance function\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "def l1_distance(vects):\n",
        "    x, y = vects\n",
        "    return K.abs(x - y)\n",
        "\n",
        "# Define contrastive loss (if used in your model)\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "def contrastive_loss(y_true, y_pred):\n",
        "    margin = 1\n",
        "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
        "\n",
        "# Optional: Euclidean distance function (if used)\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "def euclidean_distance(vects):\n",
        "    x, y = vects\n",
        "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
        "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
        "\n",
        "def verify_signature_from_path_with_display(image_path1, image_path2, model_path, threshold=0.5):\n",
        "    # Load the trained Siamese model with custom objects\n",
        "    model = load_model(model_path, custom_objects={\n",
        "        'contrastive_loss': contrastive_loss,\n",
        "        'l1_distance': l1_distance,\n",
        "        'euclidean_distance': euclidean_distance,\n",
        "        'accuracy': 'accuracy'\n",
        "    })\n",
        "\n",
        "    # Display the original signature images\n",
        "    img1_display = cv2.imread(image_path1)\n",
        "    img2_display = cv2.imread(image_path2)\n",
        "\n",
        "    if img1_display is None or img2_display is None:\n",
        "        print(\"âŒ Error: Could not load one or both images. Check the file paths.\")\n",
        "        return\n",
        "\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax[0].imshow(cv2.cvtColor(img1_display, cv2.COLOR_BGR2RGB))\n",
        "    ax[0].set_title('Signature 1')\n",
        "    ax[0].axis('off')\n",
        "    ax[1].imshow(cv2.cvtColor(img2_display, cv2.COLOR_BGR2RGB))\n",
        "    ax[1].set_title('Signature 2')\n",
        "    ax[1].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # Internal preprocessing function\n",
        "    def preprocess_image(image_path):\n",
        "        img = image.load_img(image_path, target_size=(128, 256), color_mode=\"grayscale\")\n",
        "        img_array = image.img_to_array(img)\n",
        "        img_array = cv2.adaptiveThreshold(img_array.astype(np.uint8), 255,\n",
        "                                          cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
        "        img_array = np.expand_dims(img_array, axis=-1)  # Add channel dimension\n",
        "        img_array = img_array / 255.0  # Normalize\n",
        "        return img_array\n",
        "\n",
        "    # Preprocess both images\n",
        "    sig1 = preprocess_image(image_path1)\n",
        "    sig2 = preprocess_image(image_path2)\n",
        "\n",
        "    sig1 = np.expand_dims(sig1, axis=0)  # Add batch dimension\n",
        "    sig2 = np.expand_dims(sig2, axis=0)\n",
        "\n",
        "    # Predict similarity\n",
        "    score = model.predict([sig1, sig2])[0][0]\n",
        "    print(f\"\\nSimilarity Score: {score:.4f}\")\n",
        "    print(\"âœ… Genuine\" if score <= threshold else \"âŒ Forged\")\n",
        "\n",
        "# Example usage\n",
        "verify_signature_from_path_with_display(\n",
        "    '/content/drive/MyDrive/Data/signatures/signatures_15/original_15_1.png',\n",
        "    '/content/drive/MyDrive/Data/signatures/signatures_1/original_1_1.png',\n",
        "    'siamese_model2.h5'\n",
        ")\n"
      ],
      "metadata": {
        "id": "9d9nJOHByAwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Saving the Final model(drive)**"
      ],
      "metadata": {
        "id": "n_0F8aBs59Ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/Data/saved_model/siamese_model2.h5')\n"
      ],
      "metadata": {
        "id": "eKfLEWKzzKI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Final prediction whether the two inputs are geninue or forged with reasons**"
      ],
      "metadata": {
        "id": "ojjgZlX65-Yc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model\n",
        "import cv2\n",
        "\n",
        "def verify_signature(image_path1, image_path2, model, threshold=0.6):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "        image_path1 (str): Path to first signature image\n",
        "        image_path2 (str): Path to second signature image\n",
        "        model (keras.Model): The trained Siamese model\n",
        "        threshold (float): Decision threshold for similarity score\n",
        "    \"\"\"\n",
        "\n",
        "    # 2. Load and preprocess the two images\n",
        "    def preprocess_image(img_path):\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.resize(img, (256, 128))\n",
        "        img = img.astype('float32') / 255.0\n",
        "        img = np.expand_dims(img, axis=-1)\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        return img\n",
        "\n",
        "    sig1 = preprocess_image(image_path1)\n",
        "    sig2 = preprocess_image(image_path2)\n",
        "\n",
        "    # 3. Display the images\n",
        "    img1_show = cv2.imread(image_path1)\n",
        "    img2_show = cv2.imread(image_path2)\n",
        "\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(cv2.cvtColor(img1_show, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(\"Signature 1\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(cv2.cvtColor(img2_show, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(\"Signature 2\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 4. Predict similarity score\n",
        "    score = model.predict([sig1, sig2])[0][0]\n",
        "    print(f\"Similarity Score: {score:.4f}\")\n",
        "    if score < threshold:\n",
        "        print(\"âœ… Genuine Signature\")\n",
        "        print(\"Reason:\\n\"\n",
        "      \"1. Natural Flow â€“ The pen pressure, stroke direction, and speed match the personâ€™s usual hand movement.\\n\"\n",
        "      \"2. Consistent Style â€“ Letter shapes, slant, and spacing are uniform with past verified samples.\\n\"\n",
        "      \"3. Muscle Memory â€“ Genuine signatures come from repeated use; the motion is subconscious and hard to replicate.\\n\"\n",
        "      \"4. Stable Pressure â€“ Original signatures show consistent ink pressure and pen lifts, unlike hesitations in fakes.\\n\"\n",
        "      \"5. Verified History â€“ Matches with stored digital or physical records used in banking or legal contexts.\")\n",
        "\n",
        "    else:\n",
        "        print(\"âŒ Forged Signature\")\n",
        "        print(\"Reason:\\n\"\n",
        "      \"1. Shaky Strokes â€“ Forgers often hesitate, causing unnatural or wobbly lines.\\n\"\n",
        "      \"2. Inconsistent Size â€“ Letters or signature size doesnâ€™t align with authentic records.\\n\"\n",
        "      \"3. Wrong Pen Pressure â€“ Forgeries usually show uneven or forced pen pressure.\\n\"\n",
        "      \"4. Timing Mismatch â€“ Genuine signatures take milliseconds; fakes take longer and lack fluid motion.\\n\"\n",
        "      \"5. Mismatch with Model â€“ AI models trained on hundreds of real samples detect micro-pattern mismatches no human eye can spot.\")\n"
      ],
      "metadata": {
        "id": "D_MIQlp5zMeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Final ouput**"
      ],
      "metadata": {
        "id": "2WVYB5Ay6BKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras.saving import register_keras_serializable\n",
        "\n",
        "@register_keras_serializable()\n",
        "def euclidean_distance(vectors):\n",
        "    x, y = vectors\n",
        "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
        "\n",
        "@register_keras_serializable()\n",
        "def l1_distance(vectors):\n",
        "    x, y = vectors\n",
        "    return K.abs(x - y)\n",
        "\n",
        "# Load the model with the custom objects\n",
        "model = load_model(\"/content/drive/MyDrive/Data/saved_model/siamese_model2.h5\",\n",
        "                   custom_objects={'euclidean_distance': euclidean_distance,\n",
        "                                   'l1_distance': l1_distance})\n",
        "\n",
        "# Now you can use the verify_signature function\n",
        "verify_signature(\"/content/drive/MyDrive/Data/signatures/signatures_16/original_16_22.png\",\n",
        "                 \"/content/drive/MyDrive/Data/signatures/signatures_16/original_16_22.png\",\n",
        "                 model)\n"
      ],
      "metadata": {
        "id": "w3093qFdzOpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras.saving import register_keras_serializable\n",
        "\n",
        "@register_keras_serializable()\n",
        "def euclidean_distance(vectors):\n",
        "    x, y = vectors\n",
        "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
        "\n",
        "@register_keras_serializable()\n",
        "def l1_distance(vectors):\n",
        "    x, y = vectors\n",
        "    return K.abs(x - y)\n",
        "\n",
        "# Load the model with the custom object\n",
        "model = load_model(\"/content/drive/MyDrive/Data/saved_model/siamese_model2.h5\", custom_objects={'euclidean_distance': euclidean_distance,'l1_distance': l1_distance})\n",
        "\n",
        "# Now you can use the verify_signature function\n",
        "verify_signature(\"/content/drive/MyDrive/Data/signatures/signatures_12/original_12_22.png\", \"/content/drive/MyDrive/Data/signatures/signatures_12/original_12_22.png\", model)"
      ],
      "metadata": {
        "id": "xuGsHM3hzRck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Code for Extracting Images From document**"
      ],
      "metadata": {
        "id": "uST6O8OL6JmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def pad_image(img, padding=30):\n",
        "    return cv2.copyMakeBorder(img, padding, padding, padding, padding, cv2.BORDER_CONSTANT, value=[255, 255, 255])\n",
        "\n",
        "def extract_signatures(image_path):\n",
        "    # Load the image\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        print(f\"âŒ Unable to load image: {image_path}\")\n",
        "        return\n",
        "\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    height = img.shape[0]\n",
        "\n",
        "    # Directories\n",
        "    freehand_dir = \"freehand_signatures\"\n",
        "    boxed_dir = \"boxed_signatures\"\n",
        "    os.makedirs(freehand_dir, exist_ok=True)\n",
        "    os.makedirs(boxed_dir, exist_ok=True)\n",
        "\n",
        "    # Freehand Signature Detection\n",
        "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    _, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))\n",
        "    morphed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    contours, _ = cv2.findContours(morphed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    freehand_count = 0\n",
        "    padding = 30\n",
        "\n",
        "    for cnt in contours:\n",
        "        x, y, w, h = cv2.boundingRect(cnt)\n",
        "        aspect_ratio = w / float(h)\n",
        "\n",
        "        if 100 < w < 800 and 30 < h < 300 and 1.0 < aspect_ratio < 10.0:\n",
        "            if y < height * 0.5:\n",
        "                continue\n",
        "\n",
        "            # Expand bounding box with padding\n",
        "            x_exp = max(x - padding, 0)\n",
        "            y_exp = max(y - padding, 0)\n",
        "            w_exp = min(w + 2 * padding, img.shape[1] - x_exp)\n",
        "            h_exp = min(h + 2 * padding, img.shape[0] - y_exp)\n",
        "\n",
        "            # Draw expanded bounding box in blue\n",
        "            cv2.rectangle(img, (x_exp, y_exp), (x_exp + w_exp, y_exp + h_exp), (255, 0, 0), 4)\n",
        "\n",
        "            # Crop and save the padded region\n",
        "            signature = img[y_exp:y_exp + h_exp, x_exp:x_exp + w_exp]\n",
        "            cv2.imwrite(f\"{freehand_dir}/signature_{freehand_count}.png\", signature)\n",
        "            freehand_count += 1\n",
        "\n",
        "    print(f\"ðŸ–‹ï¸ Freehand signatures extracted: {freehand_count}\")\n",
        "\n",
        "    # Boxed Signature Detection\n",
        "    edges = cv2.Canny(blur, 50, 150)\n",
        "    box_contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    boxed_count = 0\n",
        "    for cnt in box_contours:\n",
        "        approx = cv2.approxPolyDP(cnt, 0.02 * cv2.arcLength(cnt, True), True)\n",
        "\n",
        "        if len(approx) == 4 and cv2.isContourConvex(approx):\n",
        "            x, y, w, h = cv2.boundingRect(approx)\n",
        "            aspect_ratio = w / float(h)\n",
        "\n",
        "            if 50 < w < 300 and 50 < h < 300 and 0.5 < aspect_ratio < 2.0:\n",
        "                cropped = img[y:y+h, x:x+w]\n",
        "                cropped_padded = pad_image(cropped, padding=20)\n",
        "                cv2.imwrite(f\"{boxed_dir}/signature_{boxed_count}.png\", cropped_padded)\n",
        "                cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "                boxed_count += 1\n",
        "\n",
        "    print(f\"ðŸ“¦ Boxed signatures extracted: {boxed_count}\")\n",
        "\n",
        "    # Save Final Image\n",
        "    output_image_path = \"combined_signatures_marked.png\"\n",
        "    cv2.imwrite(output_image_path, img)\n",
        "    print(f\"âœ… Output image saved with all bounding boxes: {output_image_path}\")\n",
        "extract_signatures(\"signature.png\")\n"
      ],
      "metadata": {
        "id": "F4oZMrGTzYU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Comparing the Extracting images**"
      ],
      "metadata": {
        "id": "1swo1J_16KxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.saving import register_keras_serializable\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Register your custom layer functions\n",
        "@register_keras_serializable()\n",
        "def euclidean_distance(vectors):\n",
        "    x, y = vectors\n",
        "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
        "\n",
        "@register_keras_serializable()\n",
        "def l1_distance(vectors):\n",
        "    x, y = vectors\n",
        "    return K.abs(x - y)\n",
        "\n",
        "# Image preprocessing function\n",
        "def preprocess_signature(img_path):\n",
        "    img = image.load_img(img_path, target_size=(128, 256), color_mode='grayscale')\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = cv2.adaptiveThreshold(img_array.astype(np.uint8), 255,\n",
        "                                      cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                      cv2.THRESH_BINARY_INV, 11, 2)\n",
        "    img_array = np.expand_dims(img_array, axis=-1)\n",
        "    img_array = img_array / 255.0\n",
        "    return np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Verification function\n",
        "def verify_against_original(original_path, test_folder, model_path, threshold=0.6):\n",
        "    model = load_model(model_path, custom_objects={\n",
        "        'euclidean_distance': euclidean_distance,\n",
        "        'l1_distance': l1_distance\n",
        "    })\n",
        "\n",
        "    # Load the original signature for display\n",
        "    original_display = cv2.imread(original_path)\n",
        "    if original_display is None:\n",
        "        print(f\"âŒ Unable to load original image for display: {original_path}\")\n",
        "        return\n",
        "\n",
        "    # Preprocess the original signature for prediction\n",
        "    original_preprocessed = preprocess_signature(original_path)\n",
        "\n",
        "    # Loop over all extracted signatures in the folder\n",
        "    test_images = sorted(os.listdir(test_folder))\n",
        "    print(f\"\\nðŸ§ª Comparing {len(test_images)} extracted signatures against the original...\")\n",
        "\n",
        "    for filename in test_images:\n",
        "        test_path = os.path.join(test_folder, filename)\n",
        "        test_preprocessed = preprocess_signature(test_path)\n",
        "\n",
        "        # Load the test signature for display\n",
        "        test_display = cv2.imread(test_path)\n",
        "        if test_display is None:\n",
        "            print(f\"âŒ Unable to load test image for display: {test_path}\")\n",
        "            continue\n",
        "\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(cv2.cvtColor(original_display, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(\"Original Signature\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(cv2.cvtColor(test_display, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(f\"Test Signature: {filename}\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "        score = model.predict([original_preprocessed, test_preprocessed])[0][0]\n",
        "        result = \"âœ… Matching\" if score <= threshold else \"âŒ Not Matching\"\n",
        "\n",
        "        print(f\"{filename}: Similarity Score = {score:.4f} â†’ {result}\\n\")\n",
        "\n",
        "original_signature_path = \"signature1.png\"\n",
        "model_path = \"/content/drive/MyDrive/Data/saved_model/siamese_model2.h5\"\n",
        "\n",
        "verify_against_original(original_signature_path, \"freehand_signatures\", model_path)\n",
        "\n",
        "verify_against_original(original_signature_path, \"boxed_signatures\", model_path)"
      ],
      "metadata": {
        "id": "2wH1w408zbRn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}